{
 "cells": [
  {
   "source": [
    "### Eye movements Feature extraction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The feature extraction methods  used by Crabb et al. (2014) is based on count of centralised seccades. The first step is to centralise the saccades, i.e., saccades starting position is translated to (0,0) in cartesian coordinate. Then the cartesian coordinte is divided into grides in such away that each gride has a 2 by 2 degrees size. The features are the count of saccades that land in each gride."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import interp, stats, integrate\n",
    "from sklearn import svm, datasets,metrics\n",
    "import pandas as pd\n",
    "import pickle,sys,glob,os\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA,KernelPCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from numpy import random\n",
    "import random\n",
    "np.random.seed(5); random.seed(5)\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Angle_between(p1, p2):\n",
    "    \"\"\"\"\n",
    "    Angle between the horizontal line and the saccade or\n",
    "    angle between (0,0) and the end of the saccade\n",
    "    \"\"\"\n",
    "    ang1 = np.arctan2(*p1[::-1])\n",
    "    ang2 = np.arctan2(*p2[::-1])\n",
    "    return np.rad2deg((ang1 - ang2) % (2 * np.pi))\n",
    "\n",
    "def Build_2D_histogram(Amp, Ang):  \n",
    "    \"\"\"\"\n",
    "    compute 2D histogram of the saccades that land in each cartesian coordinate grid\n",
    "    \"\"\" \n",
    "    \n",
    "    Sacc_X = Amp * np.cos(Ang)\n",
    "    Sacc_Y = Amp * np.sin(Ang)\n",
    "  \n",
    "    res = np.histogram2d(Sacc_X, Sacc_Y, bins=[BINSY,BINSX])\n",
    "\n",
    "    return(res[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Process_data_stat(Df_sacc,csv_file,video):\n",
    "    \"\"\"\n",
    "    extract the saccades to compute the histogram\n",
    "    \"\"\"   \n",
    "\n",
    "    Df_saccades = Df_sacc[1:]\n",
    "    Df_saccades = Df_saccades[['metric','video','Stime','Sx','Sy','Ex','Ey','amp','vel']]        \n",
    "    Df_saccades = Df_saccades.reset_index()        \n",
    "\n",
    "    # convert time data to seconds\n",
    "    Df_saccades['amp'] = Df_saccades['amp'].astype(float)\n",
    "    Df_saccades['Stime'] = Df_saccades['Stime'].astype(float)\n",
    "    Df_saccades['Stime'] = (Df_saccades['Stime'] - Df_saccades['Stime'][0])/1000    \n",
    "\n",
    "    # exclude smaller saccades    \n",
    "    Sx = (Df_saccades.Sx).astype(float)\n",
    "    Sy = (Df_saccades.Sy).astype(float)            \n",
    "    Ex = (Df_saccades.Ex).astype(float)\n",
    "    Ey = (Df_saccades.Ey).astype(float)\n",
    "            \n",
    "    A = (Sx-Sx, Sy-Sy)\n",
    "    B = (Ex-Sx, Ey-Sy)\n",
    "    \n",
    "    ang_ = Angle_between( B,A)\n",
    "    \n",
    "    Df_saccades['Ang'] = ang_             \n",
    "    Df_saccades = Df_saccades.reset_index()    \n",
    "                \n",
    "    Res_data = Build_2D_histogram(Df_saccades.amp, Df_saccades.Ang) \n",
    "        \n",
    "    return(Res_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trials that are excluded based on the preprocesing\n",
    "CV1 = ['C003','C023','C030']\n",
    "CV2 = ['C027','C030']\n",
    "CV3 = ['C026','C027']\n",
    "\n",
    "GV1 = ['G010','G013','G024']\n",
    "GV2 = ['G003','G024','G031', 'G033']\n",
    "GV3 = ['G001','G026','G031','G036']\n",
    "\n",
    "Cvid= []\n",
    "Cvid.append(CV1)\n",
    "Cvid.append(CV2)\n",
    "Cvid.append(CV3)\n",
    "\n",
    "\n",
    "Gvid= []\n",
    "Gvid.append(GV1)\n",
    "Gvid.append(GV2)\n",
    "Gvid.append(GV3)\n",
    "\n",
    "\n",
    "Excluded_trials = {'Control':Cvid,\n",
    "'Glaucoma': Gvid}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "*********************************************\n",
      "********** processing Control data *******\n",
      "*********************************************\n",
      "Significant saccdes missing in C003 DadsArmy\n",
      "Significant saccdes missing in C023 DadsArmy\n",
      "Significant saccdes missing in C026 SkiCross\n",
      "Significant saccdes missing in C027 HistoryBoys\n",
      "Significant saccdes missing in C027 SkiCross\n",
      "Significant saccdes missing in C030 DadsArmy\n",
      "Significant saccdes missing in C030 HistoryBoys\n",
      "*********************************************\n",
      "********** processing Glaucoma data *******\n",
      "*********************************************\n",
      "Significant saccdes missing in G001 SkiCross\n",
      "Significant saccdes missing in G003 HistoryBoys\n",
      "Significant saccdes missing in G010 DadsArmy\n",
      "Significant saccdes missing in G010 HistoryBoys\n",
      "Significant saccdes missing in G010 SkiCross\n",
      "Significant saccdes missing in G013 DadsArmy\n",
      "Significant saccdes missing in G024 DadsArmy\n",
      "Significant saccdes missing in G024 HistoryBoys\n",
      "Significant saccdes missing in G026 SkiCross\n",
      "Significant saccdes missing in G031 HistoryBoys\n",
      "Significant saccdes missing in G031 SkiCross\n",
      "Significant saccdes missing in G033 HistoryBoys\n",
      "Significant saccdes missing in G036 SkiCross\n"
     ]
    }
   ],
   "source": [
    "path = '../Data'\n",
    "Saving_path = '../Features_Based_ON_Paper/'\n",
    "\n",
    "BINSX = np.array(range(-12,14,2))\n",
    "BINSY = np.array(range(-10,12,2))\n",
    "\n",
    "path = '../All_data' \n",
    "\n",
    "# path to th csv files\n",
    "sub_foldres = os.listdir(path)\n",
    "videos  = ['DadsArmy','HistoryBoys','SkiCross']\n",
    "\n",
    "Exclude = []\n",
    "for folder in sub_foldres:\n",
    "    print(f'*********************************************')\n",
    "    print(f'********** processing {folder} data *******')\n",
    "    print(f'*********************************************')\n",
    "\n",
    "    csvs = glob.glob(os.path.join(path,folder) + '/*.csv')\n",
    "\n",
    "    Exclude_vids = Excluded_trials[folder]\n",
    "    for csv in csvs:\n",
    "        dataframe = pd.read_csv(csv,  usecols=[0,1,2,3,4,5,6,7,8,9,10,11], \n",
    "                                names = ['metric','video','Eye','Stime','Etime','Duration','Sx','Sy','Ex','Ey','amp','vel'], \n",
    "                                header = None) \n",
    "                            \n",
    "        X = [];  Y = []\n",
    "        \n",
    "        for ii in range(len(videos)):\n",
    "            Exclude_vid = Exclude_vids[ii]\n",
    "            Df_saccades = dataframe[(dataframe['metric'] == 'Saccade') & (dataframe['video'] == videos[ii])]               \n",
    "\n",
    "            if len(Df_saccades.amp) > 50 and csv[-8:-4] not in Exclude_vid:                  \n",
    "                Features = Process_data_stat(Df_saccades,csv, videos[ii]) \n",
    "\n",
    "                # remove saccades smaller than 2 degrees as describe in the paper\n",
    "                Features[4:6,5:7] = np.float(\"NaN\")         \n",
    "                Features = np.array(Features).flatten()\n",
    "\n",
    "                x = Features[~np.isnan(Features)]/len(Df_saccades.amp)\n",
    "                X.append(x)\n",
    "\n",
    "            else:\n",
    "                print(f\"Significant saccdes missing in {csv[-8:-4]} {videos[ii]}\")\n",
    "                x = np.empty((116,))\n",
    "                x[:] = np.NaN\n",
    "                X.append(x)\n",
    "\n",
    "\n",
    "        if folder =='Control':\n",
    "            Y = [0,0,0]\n",
    "        else:\n",
    "            Y = [1,1,1]\n",
    "        np.save(os.path.join(Saving_path, csv[-8:-4] + '.npy'), dict(X = X,Y = Y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(3, 116)\n(3,)\n"
     ]
    }
   ],
   "source": [
    "# acessing the processed features\n",
    "re = np.load(os.path.join(Saving_path, 'G010.npy'),allow_pickle=True)\n",
    "print(np.asarray(re.item().get('X')).shape)\n",
    "print(np.asarray(re.item().get('Y')).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "a = np.array([1,1])\n",
    "b= np.array([2,2])\n",
    "np.linalg.norm(a-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "\n",
    "cc = ['C003', 'C023', 'C030']\n",
    "'ABC' not in cc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.00344828, 0.00344828, 0.        , 0.        , 0.        ,\n",
       "        0.00344828, 0.00344828, 0.00344828, 0.00689655, 0.01034483,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.00344828, 0.        ,\n",
       "        0.00344828, 0.00344828, 0.        , 0.00344828, 0.        ,\n",
       "        0.00344828, 0.00344828, 0.        , 0.        , 0.        ,\n",
       "        0.00344828, 0.        , 0.        , 0.        , 0.00344828,\n",
       "        0.        , 0.01034483, 0.00344828, 0.00689655, 0.00344828,\n",
       "        0.00689655, 0.03448276, 0.        , 0.00344828, 0.00689655,\n",
       "        0.00344828, 0.        , 0.01034483, 0.        , 0.00689655,\n",
       "        0.00344828, 0.00689655, 0.00689655, 0.02068966, 0.00344828,\n",
       "        0.00344828, 0.        , 0.        , 0.00344828, 0.00344828,\n",
       "        0.00689655, 0.0137931 , 0.01034483, 0.00689655, 0.00344828,\n",
       "        0.        , 0.00689655, 0.00344828, 0.00689655, 0.00344828,\n",
       "        0.        , 0.00689655, 0.01034483, 0.02413793, 0.00689655,\n",
       "        0.00344828, 0.        , 0.00689655, 0.        , 0.        ,\n",
       "        0.00344828, 0.        , 0.00344828, 0.        , 0.00344828,\n",
       "        0.01034483, 0.00689655, 0.00344828, 0.00344828, 0.        ,\n",
       "        0.00344828, 0.        , 0.        , 0.00689655, 0.        ,\n",
       "        0.00344828, 0.        , 0.00344828, 0.        , 0.        ,\n",
       "        0.00689655, 0.        , 0.00344828, 0.        , 0.        ,\n",
       "        0.        , 0.00689655, 0.        , 0.        , 0.00689655,\n",
       "        0.        , 0.00344828, 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [       nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan],\n",
       "       [       nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan]])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "np.asarray(re.item().get('X'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}